I"à%<ol class="bibliography"><li><span id="DiCarlo2019">Di Carlo, D., Deleforge, A., &amp; Bertin, N. (2019). Mirage: 2D Source Localization Using Microphone Pair Augmentation with Echoes. In <i>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i> (Vol. 2019-May, pp. 775â€“779). https://doi.org/10.1109/ICASSP.2019.8683534</span>

<br />

<button onclick="funToogleBottom('DiCarlo2019-bibtex')">BibTex</button>

<button onclick="funToogleBottom('DiCarlo2019-abstract')">Abstract</button>



<button class="btn"><i class="fa fa-download"></i><a href="http://dx.doi.org/10.1109/ICASSP.2019.8683534">Download</a></button>


<div id="DiCarlo2019-bibtex" style="display:none;">
    <code class="lenguage-bibtex">
        <font size="2"><pre class="collapse">@inproceedings{DiCarlo2019,
  archiveprefix = {arXiv},
  arxivid = {1906.08968},
  author = {Di Carlo, Diego and Deleforge, Antoine and Bertin, Nancy},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  doi = {10.1109/ICASSP.2019.8683534},
  eprint = {1906.08968},
  file = {:home/ddicarlo/Documents/Litterature/icassp2019{\_}mirage.pdf:pdf},
  isbn = {9781479981311},
  issn = {15206149},
  keywords = {Image Microphones,Sound Source Localization,Supervised Learning,TDOA Estimation},
  pages = {775--779},
  title = ,
  volume = {2019-May},
  year = {2019}
}
</pre></font>
    </code>
</div>

<div id="DiCarlo2019-abstract" style="display:none;">
    <p><font size="2"><i><pre class="collapse">It is commonly observed that acoustic echoes hurt per mance of sound source localization (SSL) methods. We troduce the concept of microphone array augmentation echoes (MIRAGE) and show how estimation of early-e characteristics can in fact benefit SSL. We propose a learn based scheme for echo estimation combined with a phys based scheme for echo aggregation. In a simple scenario volving 2 microphones close to a reflective surface and source, we show using simulated data that the proposed proach performs similarly to a correlation-based metho azimuth estimation while retrieving elevation as well from 2 microphones only, an impossible task in anechoic settings.</pre></i></font></p>
</div>

</li>
<li><span id="Lebarbenchon2018">Lebarbenchon, R., Camberlein, E., Di Carlo, D., Deleforge, A., &amp; Bertin, N. (2018). Evaluation of an Open-Source Implementation of the Srp-Phat Algorithm Within the 2018 Locata Challenge (pp. 2â€“3).</span>

<br />

<button onclick="funToogleBottom('Lebarbenchon2018-bibtex')">BibTex</button>




<div id="Lebarbenchon2018-bibtex" style="display:none;">
    <code class="lenguage-bibtex">
        <font size="2"><pre class="collapse">@inproceedings{Lebarbenchon2018,
  author = {Lebarbenchon, Romain and Camberlein, Ewen and {Di Carlo}, Diego and Deleforge, Antoine and Bertin, Nancy},
  file = {:home/ddicarlo/Documents/Litterature/Locata2018.pdf:pdf},
  pages = {2--3},
  title = ,
  year = {2018}
}
</pre></font>
    </code>
</div>

<div id="Lebarbenchon2018-abstract" style="display:none;">
    <p><font size="2"><i><pre class="collapse"></pre></i></font></p>
</div>

</li>
<li><span id="Scheibler2017">Scheibler, R., Di Carlo, D., Deleforge, A., &amp; Dokmanic, I. (2018). Separake: Source Separation with a Little Help from Echoes. <i>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>, 6897â€“6901. https://doi.org/10.1109/ICASSP.2018.8461345</span>

<br />

<button onclick="funToogleBottom('Scheibler2017-bibtex')">BibTex</button>

<button onclick="funToogleBottom('Scheibler2017-abstract')">Abstract</button>



<button class="btn"><i class="fa fa-download"></i><a href="http://dx.doi.org/10.1109/ICASSP.2018.8461345">Download</a></button>


<div id="Scheibler2017-bibtex" style="display:none;">
    <code class="lenguage-bibtex">
        <font size="2"><pre class="collapse">@article{Scheibler2017,
  archiveprefix = {arXiv},
  arxivid = {1711.06805},
  author = {Scheibler, Robin and Di Carlo, Diego and Deleforge, Antoine and Dokmanic, Ivan},
  doi = {10.1109/ICASSP.2018.8461345},
  eprint = {1711.06805},
  file = {:home/ddicarlo/Documents/Litterature/1711.06805.pdf:pdf},
  isbn = {9781538646588},
  issn = {15206149},
  journal = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  keywords = {Echoes,Multi-channel,NMF,Room geometry,Source separation},
  pages = {6897--6901},
  title = ,
  url = {http://arxiv.org/abs/1711.06805},
  year = {2018}
}
</pre></font>
    </code>
</div>

<div id="Scheibler2017-abstract" style="display:none;">
    <p><font size="2"><i><pre class="collapse">It is commonly believed that multipath hurts various audio processing algorithms. At odds with this belief, we show that multipath in fact helps sound source separation, even with very simple propagation models. Unlike most existing methods, we neither ignore the room impulse responses, nor we attempt to estimate them fully. We rather assume to know the positions of a few virtual microphones generated by echoes and we show how this gives us enough spatial diversity to get a performance boost over the anechoic case. We show improvements for two standard algorithms-one that uses only magnitudes of the transfer functions, and one that also uses the phases. Concretely, we show that multi-channel non-negative matrix factorization aided with a small number of echoes beats the vanilla variant of the same algorithm, and that with magnitude information only, echoes enable separation where it was previously impossible.</pre></i></font></p>
</div>

</li>
<li><span id="DiCarlo2018">Di Carlo, D., Liutkus, A., &amp; Deguemel, K. (2018). Interference reduction on full-length live recordings. In <i>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i> (Vol. 2018-April, pp. 736â€“740). https://doi.org/10.1109/ICASSP.2018.8462621</span>

<br />

<button onclick="funToogleBottom('DiCarlo2018-bibtex')">BibTex</button>

<button onclick="funToogleBottom('DiCarlo2018-abstract')">Abstract</button>



<button class="btn"><i class="fa fa-download"></i><a href="http://dx.doi.org/10.1109/ICASSP.2018.8462621">Download</a></button>


<div id="DiCarlo2018-bibtex" style="display:none;">
    <code class="lenguage-bibtex">
        <font size="2"><pre class="collapse">@inproceedings{DiCarlo2018,
  author = {Di Carlo, Diego and Liutkus, Antoine and Deguemel, Ken},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  doi = {10.1109/ICASSP.2018.8462621},
  isbn = {9781538646588},
  issn = {15206149},
  keywords = {Compressive sensing,Interference reduction,Microphone leakage,Random projection,Source separation},
  pages = {736--740},
  title = ,
  volume = {2018-April},
  year = {2018}
}
</pre></font>
    </code>
</div>

<div id="DiCarlo2018-abstract" style="display:none;">
    <p><font size="2"><i><pre class="collapse">Live concert recordings consist in long multitrack audio samples with significant interferences between channels. For audio engineering purposes, it is desirable to attenuate those interferences. Recently, we proposed an algorithm to this end based on Non-negative Matrix Factorization, that iteratively estimate the clean power spectral densities of the sources and the strength of each in each microphone signal, encoded in an interference matrix. Although it behaves well, this method is too demanding computationally for full-length concerts lasting more than one hour. In this paper, we show how random projections of the data can be leveraged for effective estimation of the parameters. Interference reduction with these ideas can be achieved on full-length live multi-track recordings in an acceptable time and could be used by sound engineers. We demonstrate the efficiency of this approach on real full-length live recordings from the Montreux Jazz Festival and also provide an implementation of the method.</pre></i></font></p>
</div>

</li>
<li><span id="DiCarlo2017">Di Carlo, D., DÃ©guernel, K., &amp; Liutkus, A. (2017). Gaussian framework for interference reduction in live recordings. In <i>Proceedings of the AES International Conference</i> (Vol. 22-24-June).</span>

<br />

<button onclick="funToogleBottom('DiCarlo2017-bibtex')">BibTex</button>

<button onclick="funToogleBottom('DiCarlo2017-abstract')">Abstract</button>




<div id="DiCarlo2017-bibtex" style="display:none;">
    <code class="lenguage-bibtex">
        <font size="2"><pre class="collapse">@inproceedings{DiCarlo2017,
  author = {Di Carlo, D. and D{\'{e}}guernel, K. and Liutkus, A.},
  booktitle = {Proceedings of the AES International Conference},
  title = ,
  volume = {22-24-June},
  year = {2017}
}
</pre></font>
    </code>
</div>

<div id="DiCarlo2017-abstract" style="display:none;">
    <p><font size="2"><i><pre class="collapse">In live multitrack recordings, each voice is usually captured by dedicated close microphones. Unfortunately, it is also captured in practice by other microphones intended for other sources, leading to so-called "interferences". Reducing this interference is desirable because it opens new perspectives for the engineering of live recordings. Hence, it has been the topic of recent research in audio processing. In this paper, we show how a Gaussian probabilistic framework may be set up for obtaining good isolation of the target sources. Doing so, we extend several state-of-the art methods by fixing some heuristic parts of their algorithms. As we show in a perceptual evaluation on real-world multitrack live recordings, the resulting principled techniques yield improved quality.</pre></i></font></p>
</div>

</li></ol>
:ET